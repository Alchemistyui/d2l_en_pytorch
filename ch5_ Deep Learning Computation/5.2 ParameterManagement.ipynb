{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "                    nn.Linear(20, 5),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(5, 10))\n",
    "        \n",
    "    def forward(self, data):\n",
    "        return self.net(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.xavier_uniform_(layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "net= MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=5, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=5, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.apply(init_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Linear(in_features=20, out_features=5, bias=True)>\n"
     ]
    }
   ],
   "source": [
    "print(net.net[0].parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targeted Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-3.1164e-01,  3.8008e-01, -2.8069e-01,  3.5592e-01,  5.7188e-02,\n",
       "          4.6611e-01, -2.1368e-01,  3.2678e-01,  4.0443e-01, -1.5698e-01,\n",
       "         -3.5363e-02,  4.0694e-01, -1.4859e-01, -3.2126e-01,  3.0339e-01,\n",
       "         -1.6407e-01, -3.7212e-01,  2.6404e-01, -2.2538e-02,  3.1528e-01],\n",
       "        [-4.5709e-01, -2.8391e-01, -2.6809e-01,  8.6438e-02, -4.7524e-01,\n",
       "         -4.0493e-01, -3.9734e-01,  2.3249e-01, -3.5679e-01, -3.8669e-01,\n",
       "          1.8968e-01,  2.4396e-01,  3.4076e-01, -4.3200e-01,  3.8828e-01,\n",
       "          3.8227e-04, -2.3610e-02, -4.7618e-01, -4.7481e-01,  4.4778e-01],\n",
       "        [ 2.7669e-01, -4.3521e-02, -1.4967e-01, -2.2915e-01,  2.4365e-01,\n",
       "         -2.1098e-01,  2.3438e-01,  3.2370e-01, -2.2168e-01, -2.0208e-01,\n",
       "          1.6742e-01, -4.8065e-01,  2.5656e-02, -4.8058e-01,  2.6327e-01,\n",
       "          1.1949e-01, -3.7686e-01,  1.3671e-01,  4.6907e-01, -4.3738e-01],\n",
       "        [-2.0126e-01, -3.1665e-01,  4.5516e-01,  1.1283e-03,  1.0312e-01,\n",
       "          5.6295e-02, -9.1094e-02,  3.6360e-02, -1.0313e-01, -2.6011e-01,\n",
       "         -5.4661e-02,  3.4017e-01, -2.3663e-01,  2.6194e-01,  3.8362e-01,\n",
       "          2.4089e-01,  1.0867e-02,  9.2022e-02, -2.9708e-01, -1.9108e-01],\n",
       "        [ 4.0544e-01,  1.9966e-01,  3.7350e-01,  3.5011e-01,  1.7382e-01,\n",
       "          3.5619e-01, -4.4391e-01, -1.2988e-01,  2.5523e-01,  6.0168e-02,\n",
       "         -2.8092e-01,  3.2719e-01, -2.9652e-01, -1.2319e-01,  1.2331e-02,\n",
       "          3.9771e-01,  1.6661e-01, -4.5981e-01, -3.7239e-01, -3.5167e-01]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([ 0.1658, -0.2065,  0.2058,  0.1433,  0.1419], requires_grad=True),\n",
       " None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net[0].bias, net.net[0].weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All parameters at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-3.1164e-01,  3.8008e-01, -2.8069e-01,  3.5592e-01,  5.7188e-02,\n",
       "                        4.6611e-01, -2.1368e-01,  3.2678e-01,  4.0443e-01, -1.5698e-01,\n",
       "                       -3.5363e-02,  4.0694e-01, -1.4859e-01, -3.2126e-01,  3.0339e-01,\n",
       "                       -1.6407e-01, -3.7212e-01,  2.6404e-01, -2.2538e-02,  3.1528e-01],\n",
       "                      [-4.5709e-01, -2.8391e-01, -2.6809e-01,  8.6438e-02, -4.7524e-01,\n",
       "                       -4.0493e-01, -3.9734e-01,  2.3249e-01, -3.5679e-01, -3.8669e-01,\n",
       "                        1.8968e-01,  2.4396e-01,  3.4076e-01, -4.3200e-01,  3.8828e-01,\n",
       "                        3.8227e-04, -2.3610e-02, -4.7618e-01, -4.7481e-01,  4.4778e-01],\n",
       "                      [ 2.7669e-01, -4.3521e-02, -1.4967e-01, -2.2915e-01,  2.4365e-01,\n",
       "                       -2.1098e-01,  2.3438e-01,  3.2370e-01, -2.2168e-01, -2.0208e-01,\n",
       "                        1.6742e-01, -4.8065e-01,  2.5656e-02, -4.8058e-01,  2.6327e-01,\n",
       "                        1.1949e-01, -3.7686e-01,  1.3671e-01,  4.6907e-01, -4.3738e-01],\n",
       "                      [-2.0126e-01, -3.1665e-01,  4.5516e-01,  1.1283e-03,  1.0312e-01,\n",
       "                        5.6295e-02, -9.1094e-02,  3.6360e-02, -1.0313e-01, -2.6011e-01,\n",
       "                       -5.4661e-02,  3.4017e-01, -2.3663e-01,  2.6194e-01,  3.8362e-01,\n",
       "                        2.4089e-01,  1.0867e-02,  9.2022e-02, -2.9708e-01, -1.9108e-01],\n",
       "                      [ 4.0544e-01,  1.9966e-01,  3.7350e-01,  3.5011e-01,  1.7382e-01,\n",
       "                        3.5619e-01, -4.4391e-01, -1.2988e-01,  2.5523e-01,  6.0168e-02,\n",
       "                       -2.8092e-01,  3.2719e-01, -2.9652e-01, -1.2319e-01,  1.2331e-02,\n",
       "                        3.9771e-01,  1.6661e-01, -4.5981e-01, -3.7239e-01, -3.5167e-01]])),\n",
       "             ('bias', tensor([ 0.1658, -0.2065,  0.2058,  0.1433,  0.1419]))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net[0].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-3.1164e-01,  3.8008e-01, -2.8069e-01,  3.5592e-01,  5.7188e-02,\n",
       "                        4.6611e-01, -2.1368e-01,  3.2678e-01,  4.0443e-01, -1.5698e-01,\n",
       "                       -3.5363e-02,  4.0694e-01, -1.4859e-01, -3.2126e-01,  3.0339e-01,\n",
       "                       -1.6407e-01, -3.7212e-01,  2.6404e-01, -2.2538e-02,  3.1528e-01],\n",
       "                      [-4.5709e-01, -2.8391e-01, -2.6809e-01,  8.6438e-02, -4.7524e-01,\n",
       "                       -4.0493e-01, -3.9734e-01,  2.3249e-01, -3.5679e-01, -3.8669e-01,\n",
       "                        1.8968e-01,  2.4396e-01,  3.4076e-01, -4.3200e-01,  3.8828e-01,\n",
       "                        3.8227e-04, -2.3610e-02, -4.7618e-01, -4.7481e-01,  4.4778e-01],\n",
       "                      [ 2.7669e-01, -4.3521e-02, -1.4967e-01, -2.2915e-01,  2.4365e-01,\n",
       "                       -2.1098e-01,  2.3438e-01,  3.2370e-01, -2.2168e-01, -2.0208e-01,\n",
       "                        1.6742e-01, -4.8065e-01,  2.5656e-02, -4.8058e-01,  2.6327e-01,\n",
       "                        1.1949e-01, -3.7686e-01,  1.3671e-01,  4.6907e-01, -4.3738e-01],\n",
       "                      [-2.0126e-01, -3.1665e-01,  4.5516e-01,  1.1283e-03,  1.0312e-01,\n",
       "                        5.6295e-02, -9.1094e-02,  3.6360e-02, -1.0313e-01, -2.6011e-01,\n",
       "                       -5.4661e-02,  3.4017e-01, -2.3663e-01,  2.6194e-01,  3.8362e-01,\n",
       "                        2.4089e-01,  1.0867e-02,  9.2022e-02, -2.9708e-01, -1.9108e-01],\n",
       "                      [ 4.0544e-01,  1.9966e-01,  3.7350e-01,  3.5011e-01,  1.7382e-01,\n",
       "                        3.5619e-01, -4.4391e-01, -1.2988e-01,  2.5523e-01,  6.0168e-02,\n",
       "                       -2.8092e-01,  3.2719e-01, -2.9652e-01, -1.2319e-01,  1.2331e-02,\n",
       "                        3.9771e-01,  1.6661e-01, -4.5981e-01, -3.7239e-01, -3.5167e-01]])),\n",
       "             ('0.bias', tensor([ 0.1658, -0.2065,  0.2058,  0.1433,  0.1419])),\n",
       "             ('2.weight',\n",
       "              tensor([[-0.6052,  0.4292, -0.2369, -0.2711, -0.4326],\n",
       "                      [ 0.1260,  0.3821, -0.4081,  0.5165, -0.5743],\n",
       "                      [-0.1924, -0.5371, -0.5032, -0.4234,  0.0499],\n",
       "                      [-0.3775,  0.4030,  0.3448,  0.1714, -0.3003],\n",
       "                      [ 0.6196,  0.2012,  0.4054,  0.3086, -0.3375],\n",
       "                      [ 0.1505, -0.3913,  0.4926, -0.2976,  0.5254],\n",
       "                      [ 0.3383, -0.3044, -0.1043,  0.4954,  0.5891],\n",
       "                      [-0.6055,  0.1088, -0.5205,  0.1154,  0.4119],\n",
       "                      [-0.2915,  0.2875,  0.5649,  0.3928,  0.3653],\n",
       "                      [ 0.2603, -0.2559,  0.2869, -0.6083, -0.4860]])),\n",
       "             ('2.bias',\n",
       "              tensor([ 3.9324e-02,  4.0156e-01,  4.3964e-01,  3.6864e-01,  8.4072e-05,\n",
       "                      -2.6539e-04, -3.5723e-01,  2.8756e-01,  3.5925e-01,  2.5525e-01]))])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.9324e-02,  4.0156e-01,  4.3964e-01,  3.6864e-01,  8.4072e-05,\n",
       "        -2.6539e-04, -3.5723e-01,  2.8756e-01,  3.5925e-01,  2.5525e-01])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net.state_dict()['2.bias']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rube Goldberg strikes again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0406,  0.0170,  0.0238, -0.0192, -0.2002, -0.0145,  0.0344,  0.0773,\n",
       "         -0.2521,  0.0359],\n",
       "        [ 0.0153,  0.0602,  0.0733, -0.0275, -0.1942, -0.0384, -0.0503,  0.0246,\n",
       "         -0.2964,  0.0327]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def block1():\n",
    "    net = nn.Sequential(nn.Linear(16, 32),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(32, 16),\n",
    "                        nn.ReLU())\n",
    "    return net\n",
    "\n",
    "def block2():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        net.add_module('block'+str(i), block1())\n",
    "    return net    \n",
    "        \n",
    "rgnet = nn.Sequential()\n",
    "rgnet.add_module('model',block2())\n",
    "rgnet.add_module('Last_linear_layer', nn.Linear(16,10))\n",
    "rgnet.apply(init_weight)\n",
    "x = torch.randn(2,16)\n",
    "rgnet(x) # forward computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (model): Sequential(\n",
      "    (block0): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block1): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block2): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block3): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (Last_linear_layer): Linear(in_features=16, out_features=10, bias=True)\n",
      ")\n",
      "torch.Size([32, 16]) torch.float32\n",
      "torch.Size([32]) torch.float32\n",
      "torch.Size([16, 32]) torch.float32\n",
      "torch.Size([16]) torch.float32\n",
      "torch.Size([32, 16]) torch.float32\n",
      "torch.Size([32]) torch.float32\n",
      "torch.Size([16, 32]) torch.float32\n",
      "torch.Size([16]) torch.float32\n",
      "torch.Size([32, 16]) torch.float32\n",
      "torch.Size([32]) torch.float32\n",
      "torch.Size([16, 32]) torch.float32\n",
      "torch.Size([16]) torch.float32\n",
      "torch.Size([32, 16]) torch.float32\n",
      "torch.Size([32]) torch.float32\n",
      "torch.Size([16, 32]) torch.float32\n",
      "torch.Size([16]) torch.float32\n",
      "torch.Size([10, 16]) torch.float32\n",
      "torch.Size([10]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(rgnet)\n",
    "for param in rgnet.parameters():\n",
    "    print(param.size(), param.dtype) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Linear(in_features=16, out_features=32, bias=True),\n",
       " tensor([ 0.0926, -0.0968, -0.1169,  0.2213, -0.0335,  0.1375, -0.1123, -0.2301,\n",
       "          0.1367, -0.0840, -0.0102, -0.2399, -0.1354,  0.0720, -0.0139, -0.2314,\n",
       "          0.1297, -0.1476,  0.2278,  0.1509, -0.2259,  0.2499, -0.2277, -0.2167,\n",
       "         -0.0845, -0.1833, -0.1025, -0.2463, -0.2133,  0.2205, -0.1539,  0.1072]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet.model.block1[0], rgnet.model.block1[0].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_parameters of Linear(in_features=16, out_features=32, bias=True)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet.model.block1[0].named_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.7215e+00,  7.8262e-01, -9.1423e-01, -1.7202e+00, -1.4108e+00,\n",
       "          9.4831e-02,  1.9820e+00,  1.3737e+00, -7.9667e-01,  2.3070e-01,\n",
       "         -2.8985e-01, -2.4998e+00,  3.5841e-01,  2.1261e+00, -2.4622e+00,\n",
       "          6.6776e-01,  6.9462e-01,  2.4012e+00,  4.1587e-02, -1.2988e+00],\n",
       "        [ 6.6969e-03, -7.5949e-01, -1.5559e+00, -1.1724e+00,  8.6252e-01,\n",
       "          6.5788e-02, -2.0958e-01,  1.2275e-01,  6.9281e-01, -1.4128e+00,\n",
       "         -2.9644e-01,  3.7062e-01, -6.9104e-01,  2.8148e-01, -7.6726e-01,\n",
       "         -5.6980e-01, -8.3769e-01, -9.5940e-01,  7.8751e-01, -4.2404e-01],\n",
       "        [ 1.9714e+00, -1.5152e+00, -7.4686e-01,  6.6779e-01, -4.6879e-01,\n",
       "          1.8414e+00, -1.8092e-01,  9.5749e-01,  1.5418e+00, -1.4059e+00,\n",
       "         -1.3374e+00, -1.6152e+00, -9.1020e-01,  3.1600e+00, -5.0846e-01,\n",
       "         -2.8166e-01,  1.5207e-01,  1.1512e+00, -3.3227e-01, -7.0956e-01],\n",
       "        [-8.7555e-01, -1.4496e+00, -6.7565e-01,  1.0525e+00, -9.0258e-01,\n",
       "         -8.5699e-01,  5.9743e-02,  2.1429e+00,  4.4680e-01,  1.0656e+00,\n",
       "          4.7227e-01,  5.6808e-04, -2.1130e-01,  1.4634e+00, -1.1729e+00,\n",
       "          2.5442e-01,  7.2890e-01, -1.5989e+00, -1.0847e+00,  6.3509e-02],\n",
       "        [-5.4947e-01, -3.7243e-01, -1.1131e+00, -1.7259e+00,  5.6068e-01,\n",
       "         -8.4026e-01,  5.7300e-01,  1.6044e+00,  2.7608e-01, -1.2096e+00,\n",
       "          1.2513e-01,  1.0640e+00,  2.0570e+00, -6.7778e-01,  1.1644e+00,\n",
       "          4.8352e-01,  2.4479e-01,  2.0001e-01, -1.4806e+00,  6.1781e-01]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gaussian_normal(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.normal_(layer.weight)\n",
    "        \n",
    "net.apply(gaussian_normal)\n",
    "net.net[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def constant(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.constant_(layer.weight, 1)\n",
    "        \n",
    "net.apply(constant)\n",
    "net.net[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('net.0.weight',\n",
       "              tensor([[ 0.4531, -0.3169,  0.3724, -0.2730, -0.1535,  0.0365,  0.1853, -0.4300,\n",
       "                       -0.4036, -0.1871, -0.4559,  0.3143, -0.3316,  0.3823, -0.3569,  0.0886,\n",
       "                       -0.3918, -0.3276,  0.0171, -0.2166],\n",
       "                      [-0.4489,  0.1880, -0.3085,  0.2780,  0.3876, -0.3468, -0.4844,  0.3453,\n",
       "                       -0.3023, -0.3810,  0.1271, -0.4123, -0.3971, -0.4346, -0.2016, -0.1957,\n",
       "                       -0.2678, -0.3830, -0.1250, -0.0430],\n",
       "                      [-0.4742, -0.2531,  0.0715, -0.4427, -0.4681, -0.2460,  0.1948, -0.2795,\n",
       "                       -0.0187,  0.4710, -0.4713,  0.4213, -0.2551, -0.3445, -0.1942, -0.0772,\n",
       "                       -0.2978, -0.2765, -0.3335, -0.3475],\n",
       "                      [ 0.3936,  0.3015, -0.2273, -0.3747, -0.1632, -0.1185,  0.0740, -0.4075,\n",
       "                       -0.1124,  0.2076,  0.2868, -0.2014,  0.3940,  0.3117,  0.1188,  0.0535,\n",
       "                        0.4276, -0.1038, -0.3740,  0.3389],\n",
       "                      [ 0.3058, -0.0072, -0.2321,  0.3390,  0.3619,  0.4552, -0.1458, -0.1575,\n",
       "                        0.0794, -0.0242,  0.0078, -0.3604, -0.3463,  0.0846, -0.1860,  0.2058,\n",
       "                        0.0966, -0.3155,  0.1815,  0.4513]])),\n",
       "             ('net.0.bias',\n",
       "              tensor([ 0.1658, -0.2065,  0.2058,  0.1433,  0.1419])),\n",
       "             ('net.2.weight',\n",
       "              tensor([[1., 1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1., 1.]])),\n",
       "             ('net.2.bias',\n",
       "              tensor([ 3.9324e-02,  4.0156e-01,  4.3964e-01,  3.6864e-01,  8.4072e-05,\n",
       "                      -2.6539e-04, -3.5723e-01,  2.8756e-01,  3.5925e-01,  2.5525e-01]))])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net[0].apply(init_weight)\n",
    "net.net[2].apply(constant)\n",
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_init(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.uniform_(layer.weight, -10, 10)\n",
    "        layer.weight.data *=  (abs(layer.weight.data) >= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('net.0.weight',\n",
       "              tensor([[ 0.0000, -0.0000,  0.0000,  5.0879,  9.5724, -5.5078,  9.8945, -5.9418,\n",
       "                        0.0000, -0.0000, -9.9102, -0.0000,  0.0000, -5.6833,  6.0102, -9.2037,\n",
       "                        0.0000,  0.0000,  7.9078, -0.0000],\n",
       "                      [ 0.0000, -0.0000,  7.4762,  5.4852, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "                       -0.0000,  0.0000, -9.1704, -8.5867,  0.0000, -7.0091, -6.8361, -6.4241,\n",
       "                       -0.0000, -9.0102, -0.0000,  0.0000],\n",
       "                      [ 5.5506, -9.5957, -8.7366,  8.1898, -0.0000,  8.8721, -0.0000,  0.0000,\n",
       "                        0.0000, -8.2533, -5.7364,  0.0000, -0.0000,  0.0000, -0.0000,  0.0000,\n",
       "                        0.0000,  0.0000, -0.0000,  5.0262],\n",
       "                      [-9.3613, -0.0000, -0.0000, -0.0000, -8.9586,  6.4050,  5.4792, -0.0000,\n",
       "                        0.0000, -0.0000,  8.6332,  6.1598, -7.7537, -0.0000,  6.4686, -0.0000,\n",
       "                       -0.0000, -9.4395, -0.0000,  0.0000],\n",
       "                      [-5.6781,  9.6903, -0.0000,  7.8520, -0.0000, -0.0000,  9.4134, -9.6457,\n",
       "                       -0.0000, -0.0000,  0.0000,  6.0993,  7.0779,  9.2863,  0.0000,  0.0000,\n",
       "                       -0.0000,  0.0000, -5.2048,  0.0000]])),\n",
       "             ('net.0.bias',\n",
       "              tensor([ 0.1658, -0.2065,  0.2058,  0.1433,  0.1419])),\n",
       "             ('net.2.weight',\n",
       "              tensor([[-0.0000,  6.9621, -0.0000,  5.3255,  8.1272],\n",
       "                      [-6.9773, -7.3306, -0.0000, -0.0000, -0.0000],\n",
       "                      [ 0.0000, -9.8917, -8.5709,  0.0000, -6.1740],\n",
       "                      [-5.0933, -0.0000,  0.0000, -7.8807, -0.0000],\n",
       "                      [ 0.0000,  6.0794,  7.1531,  6.3510, -0.0000],\n",
       "                      [-7.5778, -8.0375,  9.9850, -0.0000,  5.3504],\n",
       "                      [-5.0806,  5.9929, -8.9486, -8.0716, -9.5927],\n",
       "                      [-6.6366,  7.5533,  6.3359,  0.0000,  9.4241],\n",
       "                      [-0.0000,  6.6331,  6.4528,  8.2115, -6.0421],\n",
       "                      [ 9.0073,  5.9908,  0.0000,  0.0000,  0.0000]])),\n",
       "             ('net.2.bias',\n",
       "              tensor([ 3.9324e-02,  4.0156e-01,  4.3964e-01,  3.6864e-01,  8.4072e-05,\n",
       "                      -2.6539e-04, -3.5723e-01,  2.8756e-01,  3.5925e-01,  2.5525e-01]))])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.apply(custom_init)\n",
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.1658, -0.2065,  0.2058,  0.1433,  0.1419], requires_grad=True)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.net[0].bias[0] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 3.0000, -0.2065,  0.2058,  0.1433,  0.1419], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net[0].bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tied Parameters & Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShareModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ShareModel, self).__init__()\n",
    "        shared = nn.Linear(3,3)\n",
    "        self.net = nn.Sequential(\n",
    "                nn.Linear(2,3),\n",
    "                shared,\n",
    "                shared,\n",
    "                nn.Linear(3, 4))\n",
    "        \n",
    "    def forward(self, data):\n",
    "        return self.net(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ShareModel()\n",
    "x = torch.randn(3, 2)\n",
    "out = net(x)\n",
    "out.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('net.0.weight',\n",
       "              tensor([[-0.6898,  0.2031],\n",
       "                      [ 0.1793,  0.0130],\n",
       "                      [-0.1435,  0.1035]])),\n",
       "             ('net.0.bias', tensor([-0.0479,  0.3590,  0.3052])),\n",
       "             ('net.1.weight',\n",
       "              tensor([[-0.1917,  0.1171, -0.5175],\n",
       "                      [ 0.1423, -0.0581, -0.5330],\n",
       "                      [ 0.3312,  0.3917, -0.4905]])),\n",
       "             ('net.1.bias', tensor([ 0.2725,  0.0596, -0.2111])),\n",
       "             ('net.2.weight',\n",
       "              tensor([[-0.1917,  0.1171, -0.5175],\n",
       "                      [ 0.1423, -0.0581, -0.5330],\n",
       "                      [ 0.3312,  0.3917, -0.4905]])),\n",
       "             ('net.2.bias', tensor([ 0.2725,  0.0596, -0.2111])),\n",
       "             ('net.3.weight',\n",
       "              tensor([[-0.3348,  0.4493, -0.3914],\n",
       "                      [-0.0207, -0.0392,  0.5490],\n",
       "                      [-0.3609,  0.5214,  0.1443],\n",
       "                      [-0.5588,  0.3901, -0.0596]])),\n",
       "             ('net.3.bias', tensor([-0.1189, -0.3216,  0.4299, -0.5128]))])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net[1].weight.grad == net.net[2].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l] *",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
