{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "                    nn.Linear(20, 5),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(5, 10))\n",
    "        \n",
    "    def forward(self, data):\n",
    "        return self.net(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.xavier_uniform_(layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net= MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=5, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=5, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.apply(init_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of Linear(in_features=20, out_features=5, bias=True)>\n"
     ]
    }
   ],
   "source": [
    "print(net.net[0].parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Targeted Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.3090,  0.1840,  0.1129, -0.1278, -0.4424, -0.4689, -0.1007,  0.0250,\n",
       "         -0.1548,  0.0808,  0.3053,  0.4417,  0.1190, -0.3757, -0.0012, -0.2100,\n",
       "         -0.1744,  0.2273,  0.0871, -0.0366],\n",
       "        [-0.1260,  0.1336, -0.3288,  0.0025,  0.1394,  0.3853, -0.0126,  0.0793,\n",
       "          0.1218,  0.3870,  0.3727, -0.2385,  0.4494, -0.2669, -0.4154, -0.0372,\n",
       "         -0.0702,  0.0094,  0.2522, -0.2270],\n",
       "        [-0.1449, -0.1649, -0.3856, -0.4840, -0.3017,  0.2236, -0.2372,  0.1625,\n",
       "         -0.3108, -0.4045,  0.3918,  0.4056,  0.3551,  0.4056, -0.4010, -0.2296,\n",
       "          0.2823, -0.4041, -0.1722, -0.0367],\n",
       "        [ 0.1311, -0.4556,  0.4553,  0.2848, -0.3743,  0.1516,  0.0170,  0.0415,\n",
       "          0.3544,  0.2958, -0.4383, -0.1730,  0.0936,  0.0978,  0.2261,  0.0151,\n",
       "         -0.0805,  0.4032, -0.4339, -0.1253],\n",
       "        [-0.2712,  0.0958, -0.4718, -0.1405, -0.2407,  0.2463,  0.0369,  0.1692,\n",
       "         -0.1643,  0.2274,  0.3384,  0.0259, -0.4640,  0.2036, -0.3315, -0.0994,\n",
       "          0.0956, -0.3760,  0.2695,  0.2996]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([ 0.2235,  0.0581,  0.1642, -0.1655, -0.1108], requires_grad=True),\n",
       " None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net[0].bias, net.net[0].weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All parameters at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight',\n",
       "              tensor([[-0.3090,  0.1840,  0.1129, -0.1278, -0.4424, -0.4689, -0.1007,  0.0250,\n",
       "                       -0.1548,  0.0808,  0.3053,  0.4417,  0.1190, -0.3757, -0.0012, -0.2100,\n",
       "                       -0.1744,  0.2273,  0.0871, -0.0366],\n",
       "                      [-0.1260,  0.1336, -0.3288,  0.0025,  0.1394,  0.3853, -0.0126,  0.0793,\n",
       "                        0.1218,  0.3870,  0.3727, -0.2385,  0.4494, -0.2669, -0.4154, -0.0372,\n",
       "                       -0.0702,  0.0094,  0.2522, -0.2270],\n",
       "                      [-0.1449, -0.1649, -0.3856, -0.4840, -0.3017,  0.2236, -0.2372,  0.1625,\n",
       "                       -0.3108, -0.4045,  0.3918,  0.4056,  0.3551,  0.4056, -0.4010, -0.2296,\n",
       "                        0.2823, -0.4041, -0.1722, -0.0367],\n",
       "                      [ 0.1311, -0.4556,  0.4553,  0.2848, -0.3743,  0.1516,  0.0170,  0.0415,\n",
       "                        0.3544,  0.2958, -0.4383, -0.1730,  0.0936,  0.0978,  0.2261,  0.0151,\n",
       "                       -0.0805,  0.4032, -0.4339, -0.1253],\n",
       "                      [-0.2712,  0.0958, -0.4718, -0.1405, -0.2407,  0.2463,  0.0369,  0.1692,\n",
       "                       -0.1643,  0.2274,  0.3384,  0.0259, -0.4640,  0.2036, -0.3315, -0.0994,\n",
       "                        0.0956, -0.3760,  0.2695,  0.2996]])),\n",
       "             ('bias', tensor([ 0.2235,  0.0581,  0.1642, -0.1655, -0.1108]))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net[0].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-0.3090,  0.1840,  0.1129, -0.1278, -0.4424, -0.4689, -0.1007,  0.0250,\n",
       "                       -0.1548,  0.0808,  0.3053,  0.4417,  0.1190, -0.3757, -0.0012, -0.2100,\n",
       "                       -0.1744,  0.2273,  0.0871, -0.0366],\n",
       "                      [-0.1260,  0.1336, -0.3288,  0.0025,  0.1394,  0.3853, -0.0126,  0.0793,\n",
       "                        0.1218,  0.3870,  0.3727, -0.2385,  0.4494, -0.2669, -0.4154, -0.0372,\n",
       "                       -0.0702,  0.0094,  0.2522, -0.2270],\n",
       "                      [-0.1449, -0.1649, -0.3856, -0.4840, -0.3017,  0.2236, -0.2372,  0.1625,\n",
       "                       -0.3108, -0.4045,  0.3918,  0.4056,  0.3551,  0.4056, -0.4010, -0.2296,\n",
       "                        0.2823, -0.4041, -0.1722, -0.0367],\n",
       "                      [ 0.1311, -0.4556,  0.4553,  0.2848, -0.3743,  0.1516,  0.0170,  0.0415,\n",
       "                        0.3544,  0.2958, -0.4383, -0.1730,  0.0936,  0.0978,  0.2261,  0.0151,\n",
       "                       -0.0805,  0.4032, -0.4339, -0.1253],\n",
       "                      [-0.2712,  0.0958, -0.4718, -0.1405, -0.2407,  0.2463,  0.0369,  0.1692,\n",
       "                       -0.1643,  0.2274,  0.3384,  0.0259, -0.4640,  0.2036, -0.3315, -0.0994,\n",
       "                        0.0956, -0.3760,  0.2695,  0.2996]])),\n",
       "             ('0.bias', tensor([ 0.2235,  0.0581,  0.1642, -0.1655, -0.1108])),\n",
       "             ('2.weight',\n",
       "              tensor([[ 0.1780, -0.5834,  0.0974, -0.5874,  0.1523],\n",
       "                      [-0.4312,  0.5798, -0.1872, -0.0628,  0.4737],\n",
       "                      [-0.3148,  0.1685,  0.1345,  0.5819, -0.1589],\n",
       "                      [ 0.3637, -0.3552, -0.3367,  0.0793,  0.0177],\n",
       "                      [ 0.0807, -0.2788, -0.2719,  0.2752,  0.6009],\n",
       "                      [ 0.0675, -0.4162, -0.3975, -0.6214, -0.1756],\n",
       "                      [-0.6322,  0.1007, -0.1202,  0.3157, -0.6161],\n",
       "                      [ 0.1162, -0.0106,  0.2190, -0.4102, -0.4666],\n",
       "                      [-0.2598,  0.1337, -0.0419,  0.5472,  0.4050],\n",
       "                      [ 0.1874, -0.5594, -0.5324,  0.5865,  0.0430]])),\n",
       "             ('2.bias',\n",
       "              tensor([-0.2939, -0.0975, -0.1125, -0.3357,  0.3381,  0.2480, -0.2858,  0.1832,\n",
       "                       0.2769, -0.0832]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2939, -0.0975, -0.1125, -0.3357,  0.3381,  0.2480, -0.2858,  0.1832,\n",
       "         0.2769, -0.0832])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net.state_dict()['2.bias']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rube Goldberg strikes again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1921,  0.1614,  0.1013,  0.2589,  0.0398,  0.0767, -0.0027, -0.0177,\n",
       "         -0.1136,  0.0944],\n",
       "        [-0.1847,  0.1810,  0.0737,  0.2840,  0.0323,  0.1208, -0.0361,  0.0243,\n",
       "         -0.1105,  0.1030]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def block1():\n",
    "    net = nn.Sequential(nn.Linear(16, 32),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(32, 16),\n",
    "                        nn.ReLU())\n",
    "    return net\n",
    "\n",
    "def block2():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        net.add_module('block'+str(i), block1())\n",
    "    return net    \n",
    "        \n",
    "rgnet = nn.Sequential()\n",
    "rgnet.add_module('model',block2())\n",
    "rgnet.add_module('Last_linear_layer', nn.Linear(16,10))\n",
    "rgnet.apply(init_weight)\n",
    "x = torch.randn(2,16)\n",
    "rgnet(x) # forward computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (model): Sequential(\n",
      "    (block0): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block1): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block2): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block3): Sequential(\n",
      "      (0): Linear(in_features=16, out_features=32, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=32, out_features=16, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (Last_linear_layer): Linear(in_features=16, out_features=10, bias=True)\n",
      ")\n",
      "torch.Size([32, 16]) torch.float32\n",
      "torch.Size([32]) torch.float32\n",
      "torch.Size([16, 32]) torch.float32\n",
      "torch.Size([16]) torch.float32\n",
      "torch.Size([32, 16]) torch.float32\n",
      "torch.Size([32]) torch.float32\n",
      "torch.Size([16, 32]) torch.float32\n",
      "torch.Size([16]) torch.float32\n",
      "torch.Size([32, 16]) torch.float32\n",
      "torch.Size([32]) torch.float32\n",
      "torch.Size([16, 32]) torch.float32\n",
      "torch.Size([16]) torch.float32\n",
      "torch.Size([32, 16]) torch.float32\n",
      "torch.Size([32]) torch.float32\n",
      "torch.Size([16, 32]) torch.float32\n",
      "torch.Size([16]) torch.float32\n",
      "torch.Size([10, 16]) torch.float32\n",
      "torch.Size([10]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(rgnet)\n",
    "for param in rgnet.parameters():\n",
    "    print(param.size(), param.dtype) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Linear(in_features=16, out_features=32, bias=True),\n",
       " tensor([ 0.0373,  0.2288,  0.1572, -0.0583,  0.0834, -0.1277, -0.2312,  0.0233,\n",
       "         -0.1151,  0.1939, -0.0004, -0.2498,  0.2016,  0.2131, -0.2196, -0.1807,\n",
       "          0.2207, -0.2028, -0.0503,  0.1083, -0.0701, -0.2404, -0.1881, -0.1085,\n",
       "          0.1271, -0.1441, -0.1190,  0.0082, -0.0284, -0.1205, -0.0510, -0.0670]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet.model.block1[0], rgnet.model.block1[0].bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_parameters of Linear(in_features=16, out_features=32, bias=True)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgnet.model.block1[0].named_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.6830,  2.3053,  0.2357, -0.4555, -0.6635, -1.6496, -2.5893,  1.4305,\n",
       "          0.6197,  0.9248, -0.3411, -0.5622,  0.1512,  0.4714, -0.6439, -0.2990,\n",
       "          1.3127,  1.0076, -0.4822,  0.2196],\n",
       "        [ 0.7603, -0.6114,  0.4463,  0.4289,  1.9079, -1.6336,  0.9814,  0.0333,\n",
       "         -1.3480,  0.0652, -0.4120, -0.1600, -0.0437, -0.0521,  0.8929,  0.3791,\n",
       "         -0.5071,  0.8040,  0.2205, -0.6248],\n",
       "        [-0.2247,  1.0191, -1.0349, -1.4871,  2.2338,  0.9358,  0.9227,  0.6791,\n",
       "          0.1376,  1.4454,  0.6344,  2.0592, -0.8373, -1.5749,  0.3182, -0.0400,\n",
       "          1.4774,  0.9315, -1.5869, -0.0971],\n",
       "        [ 0.5890, -0.3836, -1.0055, -0.2519,  1.1270,  0.4325, -1.6301, -1.3290,\n",
       "         -1.2318, -1.4212, -1.2994,  0.2725,  1.0611, -0.6924,  1.7792,  1.1971,\n",
       "          0.9034, -0.1926,  0.1419, -0.6016],\n",
       "        [ 0.7491, -0.6367,  1.1025, -0.8062,  0.4488, -0.5828, -0.1888, -0.0301,\n",
       "         -0.2525, -0.8576,  0.4532,  0.7267, -0.0554,  1.5241,  0.2380,  0.4056,\n",
       "          1.0640, -1.2387, -1.1360, -1.3943]], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gaussian_normal(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.normal_(layer.weight)\n",
    "        \n",
    "net.apply(gaussian_normal)\n",
    "net.net[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def constant(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.constant_(layer.weight, 1)\n",
    "        \n",
    "net.apply(constant)\n",
    "net.net[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('net.0.weight',\n",
       "              tensor([[-0.0961,  0.3489, -0.3601,  0.4427, -0.2633, -0.3992,  0.1203, -0.1352,\n",
       "                        0.3637,  0.0562,  0.1300, -0.2271, -0.3638,  0.1306, -0.0768,  0.0853,\n",
       "                       -0.4180,  0.4230,  0.2922,  0.1488],\n",
       "                      [ 0.3007,  0.1971,  0.3760,  0.4800, -0.2691,  0.1996,  0.1697,  0.1968,\n",
       "                       -0.0361, -0.1425,  0.2101, -0.0302, -0.0837, -0.0276,  0.0220, -0.0472,\n",
       "                        0.1260, -0.0682, -0.3743,  0.0044],\n",
       "                      [ 0.1403,  0.0212,  0.4795, -0.3672,  0.3202,  0.2806, -0.3803,  0.1390,\n",
       "                       -0.3348, -0.0678,  0.0860,  0.2064, -0.1096, -0.3903, -0.1879, -0.1237,\n",
       "                        0.0391, -0.3663,  0.1962, -0.1123],\n",
       "                      [ 0.4183, -0.0812, -0.1758,  0.0711,  0.0020, -0.2695,  0.3749,  0.2725,\n",
       "                       -0.4294, -0.2714,  0.4444, -0.0824, -0.4879,  0.4694,  0.3395,  0.2755,\n",
       "                       -0.4570, -0.0020,  0.0325,  0.2865],\n",
       "                      [ 0.1714,  0.4665, -0.2667, -0.4811,  0.2582,  0.0508, -0.2045,  0.0912,\n",
       "                       -0.4514,  0.3223,  0.3035, -0.4036, -0.4005,  0.0691,  0.0474,  0.0127,\n",
       "                       -0.4841, -0.2519,  0.1141,  0.1243]])),\n",
       "             ('net.0.bias',\n",
       "              tensor([ 0.2235,  0.0581,  0.1642, -0.1655, -0.1108])),\n",
       "             ('net.2.weight',\n",
       "              tensor([[1., 1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1., 1.],\n",
       "                      [1., 1., 1., 1., 1.]])),\n",
       "             ('net.2.bias',\n",
       "              tensor([-0.2939, -0.0975, -0.1125, -0.3357,  0.3381,  0.2480, -0.2858,  0.1832,\n",
       "                       0.2769, -0.0832]))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net[0].apply(init_weight)\n",
    "net.net[2].apply(constant)\n",
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_init(layer):\n",
    "    if isinstance(layer, nn.Linear):\n",
    "        nn.init.uniform_(layer.weight, -10, 10)\n",
    "        layer.weight.data *=  (abs(layer.weight.data) >= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('net.0.weight',\n",
       "              tensor([[ 0.0000, -7.6604,  5.0198,  8.9336, -0.0000,  8.1368, -0.0000,  0.0000,\n",
       "                       -0.0000, -7.8911,  9.0172, -5.2221,  9.2773, -7.8020,  8.8087, -0.0000,\n",
       "                       -0.0000,  0.0000, -8.4649, -7.4604],\n",
       "                      [-8.0602,  0.0000, -6.0209, -0.0000,  0.0000,  8.7263,  8.1468,  8.2705,\n",
       "                       -7.7412,  0.0000,  0.0000,  7.7357, -0.0000, -0.0000,  0.0000,  0.0000,\n",
       "                        8.9293,  0.0000, -8.5831,  9.5831],\n",
       "                      [ 0.0000, -0.0000,  0.0000, -6.9102,  0.0000,  8.2808,  5.0199, -5.9622,\n",
       "                       -0.0000,  7.4637, -0.0000,  0.0000,  5.9623,  0.0000,  8.5386, -0.0000,\n",
       "                       -9.9118,  7.7232,  9.1209,  0.0000],\n",
       "                      [ 6.4823,  7.5916, -5.9966,  5.0652, -0.0000,  9.9320,  8.9006,  0.0000,\n",
       "                        0.0000,  9.4490, -0.0000, -0.0000,  8.4782,  0.0000,  5.5494, -0.0000,\n",
       "                       -5.3959, -7.0426,  7.9991,  8.0913],\n",
       "                      [-5.3325,  8.2764, -7.4285,  9.2556,  6.2396, -8.4980,  9.5223,  8.2981,\n",
       "                       -7.1795, -9.2676, -0.0000, -0.0000,  0.0000,  7.5718, -9.8995, -0.0000,\n",
       "                        5.0738,  0.0000, -0.0000,  9.3288]])),\n",
       "             ('net.0.bias',\n",
       "              tensor([ 0.2235,  0.0581,  0.1642, -0.1655, -0.1108])),\n",
       "             ('net.2.weight',\n",
       "              tensor([[ 9.0088, -8.6285, -7.5708,  0.0000, -0.0000],\n",
       "                      [ 0.0000,  0.0000, -5.8800, -0.0000, -7.4777],\n",
       "                      [-7.5027, -5.9452, -5.7641,  6.8782,  0.0000],\n",
       "                      [ 5.8667, -0.0000,  8.4949, -0.0000,  0.0000],\n",
       "                      [ 5.7245,  0.0000,  9.1556, -0.0000, -7.3039],\n",
       "                      [ 0.0000, -0.0000,  7.1487,  0.0000,  6.3514],\n",
       "                      [ 5.7110,  0.0000, -9.8475,  0.0000,  7.8531],\n",
       "                      [-0.0000,  0.0000,  5.8982,  0.0000, -9.8466],\n",
       "                      [ 0.0000, -8.7173,  8.0871,  5.5118,  0.0000],\n",
       "                      [ 6.1492, -0.0000, -0.0000,  8.7717,  6.0716]])),\n",
       "             ('net.2.bias',\n",
       "              tensor([-0.2939, -0.0975, -0.1125, -0.3357,  0.3381,  0.2480, -0.2858,  0.1832,\n",
       "                       0.2769, -0.0832]))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.apply(custom_init)\n",
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.2235,  0.0581,  0.1642, -0.1655, -0.1108], requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net[0].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.net[0].bias[0] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 3.0000,  0.0581,  0.1642, -0.1655, -0.1108], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net[0].bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tied Parameters & Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShareModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ShareModel, self).__init__()\n",
    "        shared = nn.Linear(3,3)\n",
    "        self.net = nn.Sequential(\n",
    "                nn.Linear(2,3),\n",
    "                shared,\n",
    "                shared,\n",
    "                nn.Linear(3, 4))\n",
    "        \n",
    "    def forward(self, data):\n",
    "        return self.net(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ShareModel()\n",
    "x = torch.randn(3, 2)\n",
    "out = net(x)\n",
    "out.mean().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Linear(in_features=2, out_features=3, bias=True)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net[0].parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('net.0.weight',\n",
       "              tensor([[ 0.0843, -0.3777],\n",
       "                      [ 0.3331,  0.1068],\n",
       "                      [ 0.4260,  0.1343]])),\n",
       "             ('net.0.bias', tensor([0.5181, 0.5286, 0.3189])),\n",
       "             ('net.1.weight',\n",
       "              tensor([[-0.0312, -0.4668, -0.4777],\n",
       "                      [ 0.0494,  0.1682, -0.4644],\n",
       "                      [ 0.2081,  0.2456,  0.0224]])),\n",
       "             ('net.1.bias', tensor([ 0.5437,  0.5618, -0.1748])),\n",
       "             ('net.2.weight',\n",
       "              tensor([[-0.0312, -0.4668, -0.4777],\n",
       "                      [ 0.0494,  0.1682, -0.4644],\n",
       "                      [ 0.2081,  0.2456,  0.0224]])),\n",
       "             ('net.2.bias', tensor([ 0.5437,  0.5618, -0.1748])),\n",
       "             ('net.3.weight',\n",
       "              tensor([[-0.0721, -0.4978, -0.1776],\n",
       "                      [ 0.5074, -0.4411, -0.3473],\n",
       "                      [-0.4309,  0.5612, -0.5570],\n",
       "                      [-0.4612,  0.1885,  0.3035]])),\n",
       "             ('net.3.bias', tensor([-0.1465,  0.2466,  0.0904, -0.2073]))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.net[1].weight.grad == net.net[2].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l] *",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
