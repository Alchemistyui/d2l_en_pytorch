{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "block -> nn.Module\n",
    "\n",
    "Sequential Block -> nn.Sequential ({add_module}, forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Custom Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "                    nn.Linear(20, 256),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(256, 10))\n",
    "        \n",
    "    def forward(self, data):\n",
    "        return self.net(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP().net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Sequential Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequential(nn.Sequential):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MySequential, self).__init__(**kwargs)\n",
    "        \n",
    "    def add_module(self, block):\n",
    "        self._modules[str(len(self._modules))] = block\n",
    "#         self._modules[str(type(block)).split('.')[-1].split('\\'')[0]] = block\n",
    "        \n",
    "    def forward(self, data):\n",
    "        for block in self._modules.values():\n",
    "            data = block(data)\n",
    "            \n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyMLP, self).__init__()\n",
    "        self.net = MySequential()\n",
    "        self.net.add_module(nn.Linear(20, 256))\n",
    "        self.net.add_module(nn.ReLU())\n",
    "        self.net.add_module(nn.Linear(256, 10))\n",
    "        \n",
    "    def forward(self, data):\n",
    "        return self.net(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MySequential(\n",
       "  (0): Linear(in_features=20, out_features=256, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyMLP().net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 - Parallel block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelBlock(nn.Module):\n",
    "    def __init__(self, net1, net2):\n",
    "        super(ParallelBlock, self).__init__()\n",
    "        self.net1 = net1\n",
    "        self.net2 = net2\n",
    "        \n",
    "    def forward(self, data):\n",
    "        out1 = self.net1(data)\n",
    "        out2 = self.net2(data)\n",
    "        return torch.cat((out1, out2), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1455,  0.3422,  0.1582,  0.3535, -0.1130, -0.1365, -0.1637, -0.1925,\n",
       "          -0.4087, -0.3598],\n",
       "         [-0.3239,  0.1748,  0.0075,  0.0226,  0.1066,  0.1049, -0.3315, -0.0438,\n",
       "           0.1683, -0.2228],\n",
       "         [ 0.5970, -0.6489, -0.0513,  0.4739, -0.0281,  0.0071,  0.1806, -0.2795,\n",
       "          -0.6322,  0.3603],\n",
       "         [ 0.1791,  0.0008, -0.1905,  0.3419, -0.2979, -0.2244, -0.2947, -0.1042,\n",
       "          -0.3730, -0.1888]], grad_fn=<CatBackward>),\n",
       " torch.Size([4, 10]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ParallelBlock(MLP(), MLP())\n",
    "x = torch.randn(2,20)\n",
    "out = net(x)\n",
    "out, out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 - concatenate multiple instances of the same network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factory(net_name, num):\n",
    "    net_list = []\n",
    "    for i in range(num):\n",
    "        net_list.append(net_name())\n",
    "        \n",
    "    net = nn.Sequential()\n",
    "    for idx,block in enumerate(net_list):\n",
    "        net.add_module(str(idx), block)\n",
    "        \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): MLP(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=20, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (1): MLP(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=20, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (2): MLP(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=20, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=10, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factory(MLP, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l] *",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
