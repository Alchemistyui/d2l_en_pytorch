{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7.1 Finding all the functions and classes in the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__self__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__text_signature__']\n",
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_fork_rng_warned_already', 'contextlib', 'default_generator', 'fork_rng', 'get_rng_state', 'initial_seed', 'manual_seed', 'seed', 'set_rng_state', 'warnings']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(dir(torch.tensor))\n",
    "print(dir(torch.random))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, we can ignore functions that start and end with __ (special objects in Python) or functions that start with a single _(usually internal functions). Based on the remaining function/attribute names,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the usage of specific functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function tensor:\n",
      "\n",
      "tensor(...)\n",
      "    tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False) -> Tensor\n",
      "    \n",
      "    Constructs a tensor with :attr:`data`.\n",
      "    \n",
      "    .. warning::\n",
      "    \n",
      "        :func:`torch.tensor` always copies :attr:`data`. If you have a Tensor\n",
      "        ``data`` and want to avoid a copy, use :func:`torch.Tensor.requires_grad_`\n",
      "        or :func:`torch.Tensor.detach`.\n",
      "        If you have a NumPy ``ndarray`` and want to avoid a copy, use\n",
      "        :func:`torch.as_tensor`.\n",
      "    \n",
      "    .. warning::\n",
      "    \n",
      "        When data is a tensor `x`, :func:`torch.tensor` reads out 'the data' from whatever it is passed,\n",
      "        and constructs a leaf variable. Therefore ``torch.tensor(x)`` is equivalent to ``x.clone().detach()``\n",
      "        and ``torch.tensor(x, requires_grad=True)`` is equivalent to ``x.clone().detach().requires_grad_(True)``.\n",
      "        The equivalents using ``clone()`` and ``detach()`` are recommended.\n",
      "    \n",
      "    Args:\n",
      "        data (array_like): Initial data for the tensor. Can be a list, tuple,\n",
      "            NumPy ``ndarray``, scalar, and other types.\n",
      "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "            Default: if ``None``, infers data type from :attr:`data`.\n",
      "        device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
      "            Default: if ``None``, uses the current device for the default tensor type\n",
      "            (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
      "            for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
      "        requires_grad (bool, optional): If autograd should record operations on the\n",
      "            returned tensor. Default: ``False``.\n",
      "        pin_memory (bool, optional): If set, returned tensor would be allocated in\n",
      "            the pinned memory. Works only for CPU tensors. Default: ``False``.\n",
      "    \n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]])\n",
      "        tensor([[ 0.1000,  1.2000],\n",
      "                [ 2.2000,  3.1000],\n",
      "                [ 4.9000,  5.2000]])\n",
      "    \n",
      "        >>> torch.tensor([0, 1])  # Type inference on data\n",
      "        tensor([ 0,  1])\n",
      "    \n",
      "        >>> torch.tensor([[0.11111, 0.222222, 0.3333333]],\n",
      "                         dtype=torch.float64,\n",
      "                         device=torch.device('cuda:0'))  # creates a torch.cuda.DoubleTensor\n",
      "        tensor([[ 0.1111,  0.2222,  0.3333]], dtype=torch.float64, device='cuda:0')\n",
      "    \n",
      "        >>> torch.tensor(3.14159)  # Create a scalar (zero-dimensional tensor)\n",
      "        tensor(3.1416)\n",
      "    \n",
      "        >>> torch.tensor([])  # Create an empty tensor (of size (0,))\n",
      "        tensor([])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 2.]), tensor([3, 2]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([3,2], dtype=torch.float32), torch.tensor((3,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Jupyter notebook, we can use ? to display the document in another window. For example, torch.randn? will create content that is almost identical to help(torch.randn), displaying it in a new browser window. In addition, if we use two question marks, e.g. torch.randn??, the code implementing the function will also be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l] *",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
