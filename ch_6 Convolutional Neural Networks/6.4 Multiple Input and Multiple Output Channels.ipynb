{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Input Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, kernel):\n",
    "    y_h, y_w = x.shape[0] - kernel.shape[0] + 1, x.shape[1] - kernel.shape[1] + 1\n",
    "    k_h, k_w = kernel.shape[0], kernel.shape[1]\n",
    "    y = torch.zeros(y_h, y_w)\n",
    "#     pdb.set_trace()\n",
    "    for i in range(y_h):\n",
    "        for j in range(y_w):\n",
    "#             pdb.set_trace()\n",
    "            y[i, j] = (x[i:i+k_h, j:j+k_w] * kernel).sum()\n",
    "            \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_in_conv2d(data, kernel):\n",
    "#     assert data.shape[0] == kernel.shape[0]\n",
    "#     output = torch.zeros(data.shape[1] - kernel.shape[1] + 1, data.shape[2] - kernel.shape[2] + 1)\n",
    "#     for i in range(data.shape[0]):\n",
    "#         output += conv2d(data[i], kernel[i])\n",
    "        \n",
    "#     return output\n",
    "    return sum([conv2d(x, k) for x, k in zip(data, kernel)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0, 1, 2], [3, 4, 5], [6, 7, 8]],\n",
    "                  [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "K = torch.tensor([[[0, 1], [2, 3]],\n",
    "                  [[1, 2], [3, 4]]])\n",
    "\n",
    "multi_in_conv2d(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Output Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_out_conv(data, kernel):\n",
    "    return torch.stack([multi_in_conv2d(data, sub_k) for sub_k in kernel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2, 2, 2]),\n",
       " torch.Size([3, 2, 2]),\n",
       " tensor([[[ 56.,  72.],\n",
       "          [104., 120.]],\n",
       " \n",
       "         [[ 76., 100.],\n",
       "          [148., 172.]],\n",
       " \n",
       "         [[ 96., 128.],\n",
       "          [192., 224.]]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K2 = torch.stack([K,K+1, K+2])\n",
    "K2.shape, multi_out_conv(X, K2).shape, multi_out_conv(X, K2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1Ã—1  Convolutional Layer\n",
    "\n",
    "### like fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(size=(3, 3, 3))\n",
    "K = torch.randn(size=(2, 3, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_layer(data, kernel):\n",
    "    c_i, h, w, c_o = data.shape[0], data.shape[1], data.shape[2], kernel.shape[0]\n",
    "    data = data.reshape(c_i, -1)\n",
    "    kernel = kernel.reshape(c_o, c_i)\n",
    "    return torch.mm(kernel, data).reshape(c_o, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.4097,  1.1755, -0.3172],\n",
       "          [ 1.6547, -1.2442,  1.3221],\n",
       "          [-1.3738,  0.0761, -0.4492]],\n",
       " \n",
       "         [[-1.3356, -2.6595,  2.1876],\n",
       "          [-0.6619, -0.7226, -2.3644],\n",
       "          [ 2.4354,  1.0943,  0.9356]]]),\n",
       " torch.Size([2, 3, 3]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_layer(X, K), fc_layer(X, K).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.4097,  1.1755, -0.3172],\n",
       "          [ 1.6547, -1.2442,  1.3221],\n",
       "          [-1.3738,  0.0761, -0.4492]],\n",
       " \n",
       "         [[-1.3356, -2.6595,  2.1876],\n",
       "          [-0.6619, -0.7226, -2.3644],\n",
       "          [ 2.4354,  1.0943,  0.9356]]]),\n",
       " torch.Size([2, 3, 3]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_out_conv(X, K), fc_layer(X, K).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:d2l] *",
   "language": "python",
   "name": "conda-env-d2l-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
